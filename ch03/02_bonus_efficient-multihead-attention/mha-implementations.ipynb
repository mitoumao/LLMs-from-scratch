{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e65c03-36d4-413f-9b23-5cdd816729ab",
   "metadata": {
    "id": "e2e65c03-36d4-413f-9b23-5cdd816729ab"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f678e62-7bcb-4405-86ae-dce94f494303",
   "metadata": {
    "id": "6f678e62-7bcb-4405-86ae-dce94f494303"
   },
   "source": [
    "# Comparing Efficient Multi-Head Attention Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b742938a-4bfc-4527-a1f1-d5963508967d",
   "metadata": {
    "id": "b742938a-4bfc-4527-a1f1-d5963508967d"
   },
   "source": [
    "This code notebook compares different ways to implement causal multi-head attention used in decoder-style LLMs like GPT, Llama, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7898551e-f582-48ac-9f66-3632abe2a93f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7898551e-f582-48ac-9f66-3632abe2a93f",
    "outputId": "1a7d22c1-96d8-4a42-e3ec-ce78abaf18eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "batch_size = 8\n",
    "context_len = 1024\n",
    "embed_dim = 768\n",
    "embeddings = torch.randn((batch_size, context_len, embed_dim), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LYLcq3403Yq6",
   "metadata": {
    "id": "LYLcq3403Yq6"
   },
   "source": [
    "- To run all the code in this notebook, please ensure you update to at least PyTorch 2.5 (FlexAttention is not included in earlier PyTorch releases)\n",
    "- If the code cell above shows a PyTorch version lower than 2.5, you can upgrade your PyTorch installation by uncommenting and running the following code cell (Please note that PyTorch 2.5 requires Python 3.9 or later)\n",
    "- For more specific instructions and CUDA versions, please refer to the official installation guide at https://pytorch.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db27f43-86f4-478f-89df-fbc2182a129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9bb1b6-a1e5-4e0a-884d-0f31b374a8d6",
   "metadata": {
    "id": "2f9bb1b6-a1e5-4e0a-884d-0f31b374a8d6"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 1) CausalAttention MHA wrapper class from chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "297c93ed-aec0-4896-bb89-42c4b294d3d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "297c93ed-aec0-4896-bb89-42c4b294d3d1",
    "outputId": "b6f596e4-b778-496c-bea8-3fe83d873c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CausalAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)  # New\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))  # New\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape  # New batch dimension b\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2)  # Changed transpose\n",
    "        attn_scores.masked_fill_(  # New, _ ops are in-place\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)  # New\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "class Ch03_MHA_Wrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias)\n",
    "             for _ in range(num_heads)]\n",
    "        )\n",
    "        self.out_proj = nn.Linear(d_out*num_heads, d_out*num_heads)\n",
    "\n",
    "    def forward(self, x):\n",
    "        context_vec = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        return self.out_proj(context_vec)\n",
    "\n",
    "\n",
    "mha_ch03_wrapper = Ch03_MHA_Wrapper(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim//12,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False\n",
    ").to(device)\n",
    "\n",
    "out = mha_ch03_wrapper(embeddings)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21930804-b327-40b1-8e63-94dcad39ce7b",
   "metadata": {
    "id": "21930804-b327-40b1-8e63-94dcad39ce7b"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 2) The multi-head attention class from chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ee6a61b-d25c-4a0c-8a59-f285544e3710",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ee6a61b-d25c-4a0c-8a59-f285544e3710",
    "outputId": "4d9ade55-4710-4ae6-9f00-aa87811bfb04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "class Ch03_MHA(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)  # optional projection\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "mha_ch03 = Ch03_MHA(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False\n",
    ").to(device)\n",
    "\n",
    "out = mha_ch03(embeddings)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cd11da-ea3b-4081-b483-c4965dfefbc4",
   "metadata": {
    "id": "73cd11da-ea3b-4081-b483-c4965dfefbc4"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 3) An alternative multi-head attention with combined weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa1a5ea-eaff-4d2d-aaf0-b34cdb6fd4dd",
   "metadata": {
    "id": "1fa1a5ea-eaff-4d2d-aaf0-b34cdb6fd4dd"
   },
   "source": [
    "- The code for the `MultiHeadAttentionCombinedQKV` class below is based on code that was kindly shared by [Rayed Bin Wahed](https://github.com/rasbt/LLMs-from-scratch/discussions/51)\n",
    "- The main difference between the `MultiHeadAttentionCombinedQKV` class and the `MultiHeadAttention` class used in chapter 3 is that `MultiHeadAttentionCombinedQKV` uses a single weight matrix, `self.qkv = nn.Linear(d_in, 3 * d_out, bias=qkv_bias)` instead of separate weight matrices:\n",
    "\n",
    "  - `self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)`\n",
    "  - `self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)`\n",
    "  - `self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)`\n",
    "\n",
    "- Here, `self.qkv` combines all three weight matrices `self.W_query`, `self.W_key`, and `self.W_value` to carry out the query, key, and value computation in a single step\n",
    "- Using `q, k, v = qkv.unbind(0)`, we obtain the individual query, key, and value tensors, which are then used similarly to the query, key, and value tensors in the `MultiHeadAttention` class in chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a6bd0a2-f27c-4602-afa0-c96cd295c1a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a6bd0a2-f27c-4602-afa0-c96cd295c1a6",
    "outputId": "a0a023ee-3bc7-4a89-cdba-7c97921160ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MultiHeadAttentionCombinedQKV(nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_heads, context_length, dropout=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_out % num_heads == 0, \"embed_dim is indivisible by num_heads\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.context_length = context_length\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        self.qkv = nn.Linear(d_in, 3 * d_out, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_tokens, embed_dim = x.shape\n",
    "\n",
    "        # (b, num_tokens, embed_dim) --> (b, num_tokens, 3 * embed_dim)\n",
    "        qkv = self.qkv(x)\n",
    "\n",
    "        # (b, num_tokens, 3 * embed_dim) --> (b, num_tokens, 3, num_heads, head_dim)\n",
    "        qkv = qkv.view(batch_size, num_tokens, 3, self.num_heads, self.head_dim)\n",
    "\n",
    "        # (b, num_tokens, 3, num_heads, head_dim) --> (3, b, num_heads, num_tokens, head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "\n",
    "        # (3, b, num_heads, num_tokens, head_dim) -> 3 times (b, num_head, num_tokens, head_dim)\n",
    "        queries, keys, values = qkv.unbind(0)\n",
    "\n",
    "        # (b, num_heads, num_tokens, head_dim) --> (b, num_heads, num_tokens, num_tokens)\n",
    "        attn_scores = queries @ keys.transpose(-2, -1)\n",
    "        attn_scores = attn_scores.masked_fill(\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf\n",
    "        )\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**-0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # (b, num_heads, num_tokens, num_tokens) --> (b, num_heads, num_tokens, head_dim)\n",
    "        context_vec = attn_weights @ values\n",
    "\n",
    "        # (b, num_heads, num_tokens, head_dim) --> (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = context_vec.transpose(1, 2)\n",
    "\n",
    "        # (b, num_tokens, num_heads, head_dim) --> (b, num_tokens, embed_dim)\n",
    "        context_vec = context_vec.contiguous().view(batch_size, num_tokens, embed_dim)\n",
    "\n",
    "        context_vec = self.proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "mha_combined_qkv = MultiHeadAttentionCombinedQKV(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False\n",
    ").to(device)\n",
    "\n",
    "out = mha_combined_qkv(embeddings)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14390d-3e21-43fd-87be-43e7029163ee",
   "metadata": {
    "id": "9b14390d-3e21-43fd-87be-43e7029163ee"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 4) Multi-head attention with Einsum\n",
    "\n",
    "- Implementing multi-head attention using Einstein summation via [`torch.einsum`](https://pytorch.org/docs/stable/generated/torch.einsum.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92481814-068d-439b-a65c-b1310ebbe0aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92481814-068d-439b-a65c-b1310ebbe0aa",
    "outputId": "59a75f6e-ef06-418f-8e54-d3b368fbed13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class MHAEinsum(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        # Initialize parameters for Q, K, V\n",
    "        self.W_query = nn.Parameter(torch.randn(d_out, d_in))\n",
    "        self.W_key = nn.Parameter(torch.randn(d_out, d_in))\n",
    "        self.W_value = nn.Parameter(torch.randn(d_out, d_in))\n",
    "\n",
    "        if qkv_bias:\n",
    "            self.bias_q = nn.Parameter(torch.zeros(d_out))\n",
    "            self.bias_k = nn.Parameter(torch.zeros(d_out))\n",
    "            self.bias_v = nn.Parameter(torch.zeros(d_out))\n",
    "        else:\n",
    "            self.register_parameter(\"bias_q\", None)\n",
    "            self.register_parameter(\"bias_k\", None)\n",
    "            self.register_parameter(\"bias_v\", None)\n",
    "\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.reset_parameters()\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.W_query, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_key, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_value, a=math.sqrt(5))\n",
    "        if self.bias_q is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.W_query)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias_q, -bound, bound)\n",
    "            nn.init.uniform_(self.bias_k, -bound, bound)\n",
    "            nn.init.uniform_(self.bias_v, -bound, bound)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        # Calculate Q, K, V using einsum, first perform linear transformations\n",
    "        Q = torch.einsum(\"bnd,di->bni\", x, self.W_query)\n",
    "        K = torch.einsum(\"bnd,di->bni\", x, self.W_key)\n",
    "        V = torch.einsum(\"bnd,di->bni\", x, self.W_value)\n",
    "\n",
    "        # Add biases if they are used\n",
    "        if self.bias_q is not None:\n",
    "            Q += self.bias_q\n",
    "            K += self.bias_k\n",
    "            V += self.bias_v\n",
    "\n",
    "        # Reshape for multi-head attention\n",
    "        Q = Q.view(b, n, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = K.view(b, n, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(b, n, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.einsum(\"bhnd,bhmd->bhnm\", Q, K) / (self.head_dim ** 0.5)\n",
    "\n",
    "        # Apply mask\n",
    "        mask = self.mask[:n, :n].unsqueeze(0).unsqueeze(1).expand(b, self.num_heads, n, n)\n",
    "        scores = scores.masked_fill(mask.bool(), -torch.inf)\n",
    "\n",
    "        # Softmax and dropout\n",
    "        attn_weights = torch.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Aggregate the attended context vectors\n",
    "        context_vec = torch.einsum(\"bhnm,bhmd->bhnd\", attn_weights, V)\n",
    "\n",
    "        # Combine heads and project the output\n",
    "        context_vec = context_vec.transpose(1, 2).reshape(b, n, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "mha_einsum = MHAEinsum(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False\n",
    ").to(device)\n",
    "\n",
    "out = mha_einsum(embeddings)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a042d3-ee78-4c29-bf63-d92fe6706632",
   "metadata": {
    "id": "48a042d3-ee78-4c29-bf63-d92fe6706632"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 5) Multi-head attention with PyTorch's scaled dot product attention and FlashAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e346f-3b85-44e6-9feb-f01131381148",
   "metadata": {
    "id": "f78e346f-3b85-44e6-9feb-f01131381148"
   },
   "source": [
    "- The implementation below uses PyTorch's [`scaled_dot_product_attention`](https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html) function, which implements a memory-optimized version of self-attention called [FlashAttention](https://arxiv.org/abs/2205.14135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b8e5a0d-1f65-4a03-bf6e-723f0cc428f5",
   "metadata": {
    "id": "1b8e5a0d-1f65-4a03-bf6e-723f0cc428f5"
   },
   "outputs": [],
   "source": [
    "class MHAPyTorchScaledDotProduct(nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_heads, context_length, dropout=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_out % num_heads == 0, \"embed_dim is indivisible by num_heads\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.context_length = context_length\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.d_out = d_out\n",
    "\n",
    "        self.qkv = nn.Linear(d_in, 3 * d_out, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_tokens, embed_dim = x.shape\n",
    "\n",
    "        # (b, num_tokens, embed_dim) --> (b, num_tokens, 3 * embed_dim)\n",
    "        qkv = self.qkv(x)\n",
    "\n",
    "        # (b, num_tokens, 3 * embed_dim) --> (b, num_tokens, 3, num_heads, head_dim)\n",
    "        qkv = qkv.view(batch_size, num_tokens, 3, self.num_heads, self.head_dim)\n",
    "\n",
    "        # (b, num_tokens, 3, num_heads, head_dim) --> (3, b, num_heads, num_tokens, head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "\n",
    "        # (3, b, num_heads, num_tokens, head_dim) -> 3 times (b, num_heads, num_tokens, head_dim)\n",
    "        queries, keys, values = qkv\n",
    "\n",
    "        use_dropout = 0. if not self.training else self.dropout\n",
    "\n",
    "        context_vec = nn.functional.scaled_dot_product_attention(\n",
    "            queries, keys, values, attn_mask=None, dropout_p=use_dropout, is_causal=True)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.transpose(1, 2).contiguous().view(batch_size, num_tokens, self.d_out)\n",
    "\n",
    "        context_vec = self.proj(context_vec)\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbc8ba92-3471-41cb-b1b2-4c0ef5be392b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbc8ba92-3471-41cb-b1b2-4c0ef5be392b",
    "outputId": "087a53e7-86d8-48dc-bf2e-023f0f2104cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "mha_pytorch_scaled = MHAPyTorchScaledDotProduct(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False\n",
    ").to(device)\n",
    "\n",
    "out = mha_pytorch_scaled(embeddings)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51492724-6018-49f6-8bf6-ae9e585229c3",
   "metadata": {
    "id": "51492724-6018-49f6-8bf6-ae9e585229c3"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 6) PyTorch's scaled dot product attention without FlashAttention\n",
    "\n",
    "- This is similar to above, except that we disable FlashAttention by passing an explicit causal mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bad53538-e905-4065-ba0c-caacdfec5a0b",
   "metadata": {
    "id": "bad53538-e905-4065-ba0c-caacdfec5a0b"
   },
   "outputs": [],
   "source": [
    "class MHAPyTorchSDPAWithoutFlash(nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_heads, context_length, dropout=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_out % num_heads == 0, \"embed_dim is indivisible by num_heads\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.context_length = context_length\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.d_out = d_out\n",
    "\n",
    "        self.qkv = nn.Linear(d_in, 3 * d_out, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = dropout\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1).bool())\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_tokens, embed_dim = x.shape\n",
    "\n",
    "        # (b, num_tokens, embed_dim) --> (b, num_tokens, 3 * embed_dim)\n",
    "        qkv = self.qkv(x)\n",
    "\n",
    "        # (b, num_tokens, 3 * embed_dim) --> (b, num_tokens, 3, num_heads, head_dim)\n",
    "        qkv = qkv.view(batch_size, num_tokens, 3, self.num_heads, self.head_dim)\n",
    "\n",
    "        # (b, num_tokens, 3, num_heads, head_dim) --> (3, b, num_heads, num_tokens, head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "\n",
    "        # (3, b, num_heads, num_tokens, head_dim) -> 3 times (b, num_heads, num_tokens, head_dim)\n",
    "        queries, keys, values = qkv\n",
    "\n",
    "        use_dropout = 0. if not self.training else self.dropout\n",
    "\n",
    "        # Ensure attn_mask is compatible with expected shape and `batch_first=True`\n",
    "        # No need to manually adjust for num_heads; ensure it's right for the sequence\n",
    "        if self.context_length >= num_tokens:\n",
    "            attn_mask = self.mask[:num_tokens, :num_tokens]\n",
    "        else:\n",
    "            attn_mask = self.mask[:self.context_length, :self.context_length]\n",
    "\n",
    "        context_vec = nn.functional.scaled_dot_product_attention(\n",
    "            queries, keys, values, attn_mask=attn_mask, dropout_p=use_dropout, is_causal=False)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.transpose(1, 2).contiguous().view(batch_size, num_tokens, self.d_out)\n",
    "\n",
    "        context_vec = self.proj(context_vec)\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3da7850-e772-47d3-bd51-22d077b01412",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3da7850-e772-47d3-bd51-22d077b01412",
    "outputId": "cc8fc837-8e06-42fc-bad5-b17816f47fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "mha_pytorch_sdpa_no_flash = MHAPyTorchSDPAWithoutFlash(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False\n",
    ").to(device)\n",
    "\n",
    "out = mha_pytorch_sdpa_no_flash(embeddings)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c318f-4835-4d74-8d58-a070222447c4",
   "metadata": {
    "id": "351c318f-4835-4d74-8d58-a070222447c4"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 7) Using PyTorch's torch.nn.MultiheadAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a6d060-6324-48fa-a35c-cb09f2a48965",
   "metadata": {
    "id": "74a6d060-6324-48fa-a35c-cb09f2a48965"
   },
   "source": [
    "- Below, we use PyTorch's [torch.nn.MultiheadAttention](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html) implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3799c7ef-3155-42c6-a829-f95656453ae0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3799c7ef-3155-42c6-a829-f95656453ae0",
    "outputId": "78236eea-a0f4-47e4-c846-606e7f8f8768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MHAPyTorchClass(nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_heads, context_length, dropout=0.0, qkv_bias=False, need_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.context_length = context_length\n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            embed_dim=d_out,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            bias=qkv_bias,\n",
    "            add_bias_kv=qkv_bias,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.need_weights = need_weights\n",
    "        self.proj = nn.Linear(d_out, d_out)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1).bool())\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_tokens, _ = x.shape\n",
    "\n",
    "        # Ensure attn_mask is compatible with expected shape and `batch_first=True`\n",
    "        # No need to manually adjust for num_heads; ensure it's right for the sequence\n",
    "        if self.context_length >= num_tokens:\n",
    "            attn_mask = self.mask[:num_tokens, :num_tokens]\n",
    "        else:\n",
    "            attn_mask = self.mask[:self.context_length, :self.context_length]\n",
    "\n",
    "        # attn_mask broadcasting will handle batch_size dimension implicitly\n",
    "        attn_output, _ = self.multihead_attn(\n",
    "            x, x, x, attn_mask=attn_mask, need_weights=self.need_weights\n",
    "        )\n",
    "\n",
    "        output = self.proj(attn_output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "mha_pytorch_class_default = MHAPyTorchClass(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False\n",
    ").to(device)\n",
    "\n",
    "out = mha_pytorch_class_default(embeddings)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3953bff-1056-4de2-bfd1-dfccf659eee4",
   "metadata": {
    "id": "a3953bff-1056-4de2-bfd1-dfccf659eee4"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 8) Using PyTorch's torch.nn.MultiheadAttention with `scaled_dot_product_attention`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2164859-31a0-4537-b4fb-27d57675ba77",
   "metadata": {
    "id": "d2164859-31a0-4537-b4fb-27d57675ba77"
   },
   "source": [
    "- Set `need_weights` (default `True`) to `False` so that `MultiheadAttention` uses `scaled_dot_product_attention` [according to the documentation](https://github.com/pytorch/pytorch/blob/71d020262793542974cf13b30f2a9099773f015c/torch/nn/modules/activation.py#L1096)\n",
    "\n",
    "```markdown\n",
    "need_weights: If specified, returns `attn_output_weights` in addition to `attn_outputs`.\n",
    "           Set `need_weights=False` to use the optimized `scaled_dot_product_attention`\n",
    "           and achieve the best performance for MHA.\n",
    "           Default: `True`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a4c2afe-5e1f-4bd7-a118-67031176f147",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4a4c2afe-5e1f-4bd7-a118-67031176f147",
    "outputId": "6359dcff-ddcf-4cf9-eada-c3f0685cced2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "mha_pytorch_class_noweights = MHAPyTorchClass(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False,\n",
    "    need_weights=False # NEW!\n",
    ").to(device)\n",
    "\n",
    "out = mha_pytorch_class_noweights(embeddings)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f4ff35-651c-4e47-bfa1-016f3de01ecc",
   "metadata": {
    "id": "21f4ff35-651c-4e47-bfa1-016f3de01ecc"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 9) Using PyTorch's FlexAttention\n",
    "\n",
    "- See [FlexAttention: The Flexibility of PyTorch with the Performance of FlashAttention](https://pytorch.org/blog/flexattention/) to learn more about FlexAttention\n",
    "- This is supported starting from PyTorch 2.5, which you can install on a CPU machine via\n",
    "\n",
    "    ```bash\n",
    "    pip install torch torchvision torchaudio\n",
    "    ```\n",
    "\n",
    "- To install PyTorch on a GPU machine, use the following (for more information, also see the installation menu on [pytorch.org](https://pytorch.org/))\n",
    "\n",
    "    ```bash\n",
    "    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "834318c8-4748-4902-99f0-70ee02bef63e",
   "metadata": {
    "id": "834318c8-4748-4902-99f0-70ee02bef63e"
   },
   "outputs": [],
   "source": [
    "from packaging.version import parse as parse_version\n",
    "\n",
    "def normalize_version(version):\n",
    "    parsed_version = parse_version(version)\n",
    "    return parse_version(f\"{parsed_version.major}.{parsed_version.minor}.{parsed_version.micro}\")\n",
    "\n",
    "current_version = normalize_version(torch.__version__)\n",
    "MIN_TORCH_VERSION = \"2.5.0\"\n",
    "required_version = parse_version(MIN_TORCH_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "WYyFRCXndVH9",
   "metadata": {
    "id": "WYyFRCXndVH9"
   },
   "outputs": [],
   "source": [
    "if current_version >= required_version:\n",
    "    from torch.nn.attention.flex_attention import flex_attention, create_block_mask\n",
    "\n",
    "\n",
    "def causal(b, h, q_idx, kv_idx):\n",
    "    return q_idx >= kv_idx\n",
    "\n",
    "\n",
    "class MHAPyTorchFlexAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, num_heads, context_length, dropout=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_out % num_heads == 0, \"embed_dim is indivisible by num_heads\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.context_length = context_length\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.d_out = d_out\n",
    "\n",
    "        self.qkv = nn.Linear(d_in, 3 * d_out, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = dropout\n",
    "        # self.register_buffer(\"block_mask\", create_block_mask(causal, B=None, H=None, Q_LEN=context_length, KV_LEN=context_length))\n",
    "        # `create_block_mask` function does not support buffers, yet\n",
    "        self.block_mask = create_block_mask(causal, B=None, H=None, Q_LEN=context_length, KV_LEN=context_length)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_tokens, embed_dim = x.shape\n",
    "\n",
    "        # (b, num_tokens, embed_dim) --> (b, num_tokens, 3 * embed_dim)\n",
    "        qkv = self.qkv(x)\n",
    "\n",
    "        # (b, num_tokens, 3 * embed_dim) --> (b, num_tokens, 3, num_heads, head_dim)\n",
    "        qkv = qkv.view(batch_size, num_tokens, 3, self.num_heads, self.head_dim)\n",
    "\n",
    "        # (b, num_tokens, 3, num_heads, head_dim) --> (3, b, num_heads, num_tokens, head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "\n",
    "        # (3, b, num_heads, num_tokens, head_dim) -> 3 times (b, num_heads, num_tokens, head_dim)\n",
    "        queries, keys, values = qkv\n",
    "\n",
    "        use_dropout = 0. if not self.training else self.dropout\n",
    "\n",
    "        # Ensure attn_mask is compatible with expected shape and `batch_first=True`\n",
    "        # No need to manually adjust for num_heads; ensure it's right for the sequence\n",
    "        if self.context_length >= num_tokens:\n",
    "            attn_mask = self.block_mask[:num_tokens, :num_tokens]\n",
    "        else:\n",
    "            attn_mask = self.block_mask[:self.context_length, :self.context_length]\n",
    "\n",
    "        context_vec = flex_attention(queries, keys, values, block_mask=attn_mask)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.transpose(1, 2).contiguous().view(batch_size, num_tokens, self.d_out)\n",
    "\n",
    "        context_vec = self.proj(context_vec)\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cdaaf8a-f956-44bc-932f-4d33448e8aaf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cdaaf8a-f956-44bc-932f-4d33448e8aaf",
    "outputId": "a88a7398-159e-401f-d96c-2fc928908e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "if current_version >= required_version and torch.cuda.is_available():\n",
    "\n",
    "    mha_pytorch_flex = MHAPyTorchFlexAttention(\n",
    "        d_in=embed_dim,\n",
    "        d_out=embed_dim,\n",
    "        context_length=context_len,\n",
    "        dropout=0.0,\n",
    "        num_heads=12,\n",
    "        qkv_bias=False\n",
    "    ).to(device)\n",
    "\n",
    "    out = mha_pytorch_flex(embeddings)\n",
    "    print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8877de71-f84f-4f6d-bc87-7552013b6301",
   "metadata": {
    "id": "8877de71-f84f-4f6d-bc87-7552013b6301"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## Quick speed comparison (M3 Macbook Air CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "219cf93a-078f-434d-888c-2458d0731285",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "219cf93a-078f-434d-888c-2458d0731285",
    "outputId": "a10b52d4-b4e6-43c2-9677-113c41edd3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu118\n",
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Running on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a97c0b2e-6593-49d8-98bc-2267b3aa610f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a97c0b2e-6593-49d8-98bc-2267b3aa610f",
    "outputId": "7bcd7da4-d115-4ba6-efba-377a0bd7d3a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.63 ms ± 51.7 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 1) CausalAttention MHA wrapper class from chapter 3\n",
    "%timeit mha_ch03_wrapper(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19db9c2c-8e75-431a-8eef-0b4d8284e6e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19db9c2c-8e75-431a-8eef-0b4d8284e6e6",
    "outputId": "b04b4d0d-71aa-4944-f02b-131bf5a50202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.09 ms ± 45.6 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 2) The multi-head attention class from chapter 3\n",
    "%timeit mha_ch03(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa526ee0-7a88-4f34-a49a-f8f97da83779",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa526ee0-7a88-4f34-a49a-f8f97da83779",
    "outputId": "5436928a-7b98-4c40-bf51-97973f13327e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.33 ms ± 59.3 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 3) An alternative multi-head attention with combined weights\n",
    "%timeit mha_combined_qkv(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "131ca826-35bf-47e5-b497-540aba439ef9",
   "metadata": {
    "id": "131ca826-35bf-47e5-b497-540aba439ef9",
    "outputId": "f5848852-f81b-4e5f-a7ff-e37a8445ad91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.74 ms ± 60 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 4) Multi-head attention using Einstein summation\n",
    "%timeit mha_einsum(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc2b4256-16d8-4c34-9fd0-d4b4af0e60fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc2b4256-16d8-4c34-9fd0-d4b4af0e60fa",
    "outputId": "9e07ce73-a2de-4e2c-8276-64626df9450e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5 ms ± 4.58 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 5) Multi-head attention with PyTorch's scaled dot product attention\n",
    "%timeit mha_pytorch_scaled(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c44305ce-9f61-451a-b9ef-30caba222357",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c44305ce-9f61-451a-b9ef-30caba222357",
    "outputId": "6bab4a24-5bb4-4ad6-b260-3b442f598950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.54 ms ± 307 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 6) PyTorch's scaled dot product attention without FlashAttention\n",
    "%timeit mha_pytorch_sdpa_no_flash(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f209e70-ebb6-4a1a-b608-1ff42e41c01d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f209e70-ebb6-4a1a-b608-1ff42e41c01d",
    "outputId": "630c49d1-8a06-4148-cd96-a7b2467310a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.97 ms ± 116 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 7) Using PyTorch's torch.nn.MultiheadAttention\n",
    "%timeit mha_pytorch_class_default(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f4968c2-8d40-4ab9-8dba-052b4f77d756",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f4968c2-8d40-4ab9-8dba-052b4f77d756",
    "outputId": "10f6a268-f9cf-446c-aa83-e87b6a0b4f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.19 ms ± 59.6 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 8) Using PyTorch's torch.nn.MultiheadAttention disabling `need_weights`\n",
    "%timeit mha_pytorch_class_noweights(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdd8e0fc-ef24-424c-bccf-c381e73da228",
   "metadata": {
    "id": "bdd8e0fc-ef24-424c-bccf-c381e73da228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.1 ms ± 306 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "## 9) Using PyTorch's FlexAttention\n",
    "\n",
    "# Requires PyTorch 2.5.0 or newer and currently only supports CUDA PyTorch\n",
    "%timeit mha_pytorch_flex(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ff594-6cc2-496d-a302-789fa104c3c9",
   "metadata": {
    "id": "a78ff594-6cc2-496d-a302-789fa104c3c9"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## Quick speed comparison (Nvidia A100 GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "RStnI1pEi6Eo",
   "metadata": {
    "id": "RStnI1pEi6Eo"
   },
   "outputs": [],
   "source": [
    "# Enable tensor cores\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8431d75-e1c9-4d9a-b7da-9a1ff391f2bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8431d75-e1c9-4d9a-b7da-9a1ff391f2bf",
    "outputId": "f6356d4c-7a3f-47f5-cf51-5507db3f5748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu118\n",
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Running on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "707a2a14-a089-48a8-88aa-d328e1e0a9d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "707a2a14-a089-48a8-88aa-d328e1e0a9d0",
    "outputId": "4ea5798b-a590-401b-d049-3fed0716db34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.75 ms ± 54.3 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 1) CausalAttention MHA wrapper class from chapter 3\n",
    "%timeit mha_ch03_wrapper(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8686dd69-3655-40e4-a57b-a2c55532a010",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8686dd69-3655-40e4-a57b-a2c55532a010",
    "outputId": "88094b61-4d87-47bd-8c8b-c9344ab57062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.58 ms ± 38.9 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 2) The multi-head attention class from chapter 3\n",
    "%timeit mha_ch03(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2209d7df-e54b-4910-ae2b-c78cf684d9bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2209d7df-e54b-4910-ae2b-c78cf684d9bf",
    "outputId": "e3d82c53-f75b-425a-ed3e-5e48ea9ef768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.8 ms ± 52.6 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 3) An alternative multi-head attention with combined weights\n",
    "%timeit mha_combined_qkv(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "abee5edf-2585-4f0e-846c-b1c7ca88f545",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abee5edf-2585-4f0e-846c-b1c7ca88f545",
    "outputId": "c9bf17f5-de62-4c39-a328-fe430812b156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.37 ms ± 110 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 4) Multi-head attention using Einstein summation\n",
    "%timeit mha_einsum(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1075abe2-4839-4fd6-af3e-c09bb3651e26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1075abe2-4839-4fd6-af3e-c09bb3651e26",
    "outputId": "b63f4769-3be5-44df-b8f2-2ac379be1ff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.91 ms ± 6.92 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 5) Multi-head attention with PyTorch's scaled dot product attention\n",
    "%timeit mha_pytorch_scaled(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "218adbaf-f17f-47d9-81d5-41c758218df7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "218adbaf-f17f-47d9-81d5-41c758218df7",
    "outputId": "a30ab365-865d-4175-f148-dc15abc4e07a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9 ms ± 197 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 6) PyTorch's scaled dot product attention without FlashAttention\n",
    "%timeit mha_pytorch_sdpa_no_flash(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "868e3670-8edc-47bc-9e06-eb505e44dc9d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "868e3670-8edc-47bc-9e06-eb505e44dc9d",
    "outputId": "e20e77ac-6573-4830-82c7-795bd139af4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.27 ms ± 76.7 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 7) Using PyTorch's torch.nn.MultiheadAttention\n",
    "%timeit mha_pytorch_class_default(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "944870e6-de54-4e3b-a455-b8f21f6f92c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "944870e6-de54-4e3b-a455-b8f21f6f92c8",
    "outputId": "26df6295-fa5c-4b3f-89be-c7183f079fce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.44 ms ± 87.8 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 8) Using PyTorch's torch.nn.MultiheadAttention disabling `need_weights`\n",
    "%timeit mha_pytorch_class_noweights(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "evKtpb5QN_2A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "evKtpb5QN_2A",
    "outputId": "23bf5398-c8ec-4463-8af9-17de8f920a33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.1 ms ± 208 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "## 9) Using PyTorch's FlexAttention\n",
    "\n",
    "# Requires PyTorch 2.5.0 or newer\n",
    "%timeit mha_pytorch_flex(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabc6575-0316-4640-a729-e616d5c17b73",
   "metadata": {
    "id": "dabc6575-0316-4640-a729-e616d5c17b73"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbb2f729-d3d8-46d0-b249-9249197ea574",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbb2f729-d3d8-46d0-b249-9249197ea574",
    "outputId": "a45fe256-6416-4f43-87d2-27bbf97239e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu118\n",
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Running on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0620bf5",
   "metadata": {
    "id": "b0620bf5"
   },
   "outputs": [],
   "source": [
    "functions = {\n",
    "    \"1) MHA wrapper class\": mha_ch03_wrapper,\n",
    "    \"2) MHA Ch03\": mha_ch03,\n",
    "    \"3) MHA with combined QKV weights\": mha_combined_qkv,\n",
    "    \"4) MHA with Einsum\": mha_einsum,\n",
    "    \"5) MHA with PyTorch scaled_dot_product_attention\": mha_pytorch_scaled,\n",
    "    \"6) PyTorch's SDPA, no FlashAttention\": mha_pytorch_sdpa_no_flash,\n",
    "    \"7) PyTorch MHA class defaults\": mha_pytorch_class_default,\n",
    "    \"8) PyTorch MHA with need_weights=False\": mha_pytorch_class_noweights\n",
    "    }\n",
    "\n",
    "if current_version >= required_version:\n",
    "    functions[\"8) PyTorch's FlexAttention\"] =  mha_pytorch_flex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "CDJAPZaszaqx",
   "metadata": {
    "id": "CDJAPZaszaqx"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Customize further for dark mode aesthetics\n",
    "plt.rcParams[\"figure.facecolor\"] = \"#121212\"\n",
    "plt.rcParams[\"axes.facecolor\"] = \"#121212\"\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"white\"\n",
    "plt.rcParams[\"axes.labelcolor\"] = \"white\"\n",
    "plt.rcParams[\"text.color\"] = \"white\"\n",
    "plt.rcParams[\"xtick.color\"] = \"white\"\n",
    "plt.rcParams[\"ytick.color\"] = \"white\"\n",
    "plt.rcParams[\"grid.color\"] = \"#444444\"\n",
    "plt.rcParams[\"lines.linewidth\"] = 2\n",
    "plt.rcParams[\"lines.markersize\"] = 8\n",
    "\n",
    "def plot_execution_times(functions, execution_means, execution_stds, filename):\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots()\n",
    "    bars = ax.bar(functions.keys(), execution_means, yerr=execution_stds, capsize=5, error_kw={'ecolor': 'grey'})\n",
    "\n",
    "    plt.ylabel(\"Execution time (ms)\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "    # Calculate new ylim with a margin\n",
    "    max_execution_time = max(execution_means)\n",
    "    upper_ylim = max_execution_time + 0.4 * max_execution_time  # Adding a 40% margin\n",
    "    plt.ylim(0, upper_ylim)\n",
    "\n",
    "    # Annotate bars with execution times\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval + (0.05 * upper_ylim), round(yval, 2), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df834dc",
   "metadata": {
    "id": "4df834dc"
   },
   "source": [
    "## Speed comparison (Nvidia A100 GPU) with warmup (forward pass only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29b63d3d-6d0b-43bb-9c68-d5514dc81000",
   "metadata": {
    "id": "29b63d3d-6d0b-43bb-9c68-d5514dc81000"
   },
   "outputs": [],
   "source": [
    "# CUDA benchmark code shared by Andrei Aksionov\n",
    "# and based on code from\n",
    "# https://github.com/cuda-mode/lectures/blob/main/lecture1/pytorch_square.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def time_pytorch_function(func, *input, num_repeats=1_000):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(5):\n",
    "        func(*input)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    times = []\n",
    "    for _ in range(num_repeats):\n",
    "        start.record()\n",
    "        func(*input)\n",
    "        end.record()\n",
    "        torch.cuda.synchronize()\n",
    "        times.append(start.elapsed_time(end))\n",
    "\n",
    "    return np.mean(times), np.std(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9dd07a09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "9dd07a09",
    "outputId": "491d06f4-a6bc-431a-a1ca-4db38df57e0c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "execution_stats = [time_pytorch_function(fn, embeddings) for fn in functions.values()]\n",
    "execution_means = [stat[0] for stat in execution_stats]\n",
    "execution_stds = [stat[1] for stat in execution_stats]\n",
    "\n",
    "\n",
    "plot_execution_times(functions, execution_means, execution_stds, filename=\"1_forward-only.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VQaSerWCOnYB",
   "metadata": {
    "id": "VQaSerWCOnYB"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "## Speed comparison (Nvidia A100 GPU) with warmup (forward and backward pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69e6377b",
   "metadata": {
    "id": "69e6377b"
   },
   "outputs": [],
   "source": [
    "def forward_backward(func, embeddings):\n",
    "    if embeddings.grad is not None:\n",
    "        embeddings.grad.zero_()\n",
    "\n",
    "    output = func(embeddings)\n",
    "    loss = output.sum()\n",
    "    loss.backward()\n",
    "\n",
    "\n",
    "def time_pytorch_function_forward_backward(func, *input, num_repeats = 1_000):\n",
    "    # CUDA IS ASYNC so can't use python time module\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(5):\n",
    "        forward_backward(func, *input)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    times = []\n",
    "    for _ in range(num_repeats):\n",
    "        start.record()\n",
    "        forward_backward(func, *input)\n",
    "        end.record()\n",
    "        torch.cuda.synchronize()\n",
    "        times.append(start.elapsed_time(end))\n",
    "\n",
    "    return np.mean(times), np.std(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ReCmeRhCOpm8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "ReCmeRhCOpm8",
    "outputId": "2bcfa909-ba87-4d31-b926-bc66e63736cc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "execution_stats = [time_pytorch_function_forward_backward(fn, embeddings) for fn in functions.values()]\n",
    "execution_means = [stat[0] for stat in execution_stats]\n",
    "execution_stds = [stat[1] for stat in execution_stats]\n",
    "\n",
    "\n",
    "plot_execution_times(functions, execution_means, execution_stds, filename=\"2_forward-and-backward.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1gWX-Ayqia1k",
   "metadata": {
    "id": "1gWX-Ayqia1k"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "## Speed comparison (Nvidia A100 GPU) with warmup and compilation (forward and backward pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "LQDiAPooiYAz",
   "metadata": {
    "id": "LQDiAPooiYAz"
   },
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "def prepare_function(fn):\n",
    "    fn = torch.compile(fn)\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aac06ffe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "aac06ffe",
    "outputId": "098c66b4-1201-4bdd-af23-e634f5ade806"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\huzhe\\AppData\\Local\\Temp\\ipykernel_3148\\2518120624.py line 40 \n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:04:19.251000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\huzhe\\AppData\\Local\\Temp\\ipykernel_3148\\2518120624.py line 14 \n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:04:19.398000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\huzhe\\AppData\\Local\\Temp\\ipykernel_3148\\2980611749.py line 17 \n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:04:32.710000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\huzhe\\AppData\\Local\\Temp\\ipykernel_3148\\4223430686.py line 22 \n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:04:52.264000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\huzhe\\AppData\\Local\\Temp\\ipykernel_3148\\2496309509.py line 47 \n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:05:13.019000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\huzhe\\AppData\\Local\\Temp\\ipykernel_3148\\906077904.py line 16 \n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1784, in codegen\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler.codegen()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3383, in codegen\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._codegen()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3474, in _codegen\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     if device is not None and self.get_backend(device).ready_to_flush():\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1784, in codegen\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler.codegen()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3383, in codegen\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._codegen()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3474, in _codegen\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     if device is not None and self.get_backend(device).ready_to_flush():\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:05:34.468000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\huzhe\\AppData\\Local\\Temp\\ipykernel_3148\\3282155839.py line 17 \n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:05:41.889000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\huzhe\\AppData\\Local\\Temp\\ipykernel_3148\\1444845809.py line 22 \n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:05:53.369000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\huzhe\\AppData\\Local\\Temp\\ipykernel_3148\\3807752116.py line 29 \n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1370, in load\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 859, in fx_codegen_and_compile\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     graph.run(*example_inputs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 780, in run\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return super().run(*args)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\fx\\interpreter.py\", line 146, in run\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.env[node] = self.run_node(node)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1319, in run_node\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = super().run_node(n)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\fx\\interpreter.py\", line 203, in run_node\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1024, in call_function\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise LoweringException(e, target, args, kwargs).with_traceback(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1021, in call_function\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = lowerings[target](*args, **kwargs)  # type: ignore[index]\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\lowering.py\", line 361, in wrapped\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = decomp_fn(*args, **kwargs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\kernel\\flex_attention.py\", line 849, in flex_attention\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     flex_attention_template.maybe_append_choice(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codegen\\common.py\", line 2158, in maybe_append_choice\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     choices.append(self.generate(**kwargs))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 678, in generate\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code = template.finalize_all()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 102, in finalize_all\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.code = self.code.replace(key, fn())\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                        ^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 306, in hook\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code.splice(self.jit_lines())\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                 ^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 232, in jit_lines\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     **TritonKernel.inductor_meta_common(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 2532, in inductor_meta_common\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\utils\\_triton.py\", line 51, in triton_hash_with_backend\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     from triton.compiler.compiler import triton_key\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._inductor.exc.LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=768),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_1])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=1536),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_2])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_2])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_4])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_6])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_8])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf3, i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf5, i3 + 8 * i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_1,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type_1, clone_1, sort])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf13', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf10, i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type_2,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type_2])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf14', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf12, i3 + 8 * i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_3,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([sort_1, clone_3, convert_element_type_3])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=768),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_1])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=1536),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_2])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_2])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_4])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_6])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_8])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf3, i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf5, i3 + 8 * i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_1,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type_1, clone_1, sort])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf13', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf10, i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type_2,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type_2])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf14', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf12, i3 + 8 * i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_3,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([sort_1, clone_3, convert_element_type_3])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1370, in load\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 859, in fx_codegen_and_compile\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     graph.run(*example_inputs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 780, in run\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return super().run(*args)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\fx\\interpreter.py\", line 146, in run\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.env[node] = self.run_node(node)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1319, in run_node\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = super().run_node(n)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\fx\\interpreter.py\", line 203, in run_node\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1024, in call_function\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise LoweringException(e, target, args, kwargs).with_traceback(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1021, in call_function\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = lowerings[target](*args, **kwargs)  # type: ignore[index]\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\lowering.py\", line 361, in wrapped\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = decomp_fn(*args, **kwargs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\kernel\\flex_attention.py\", line 849, in flex_attention\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     flex_attention_template.maybe_append_choice(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codegen\\common.py\", line 2158, in maybe_append_choice\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     choices.append(self.generate(**kwargs))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 678, in generate\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code = template.finalize_all()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 102, in finalize_all\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.code = self.code.replace(key, fn())\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                        ^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 306, in hook\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code.splice(self.jit_lines())\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                 ^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 232, in jit_lines\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     **TritonKernel.inductor_meta_common(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 2532, in inductor_meta_common\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\utils\\_triton.py\", line 51, in triton_hash_with_backend\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     from triton.compiler.compiler import triton_key\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._inductor.exc.LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=768),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_1])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=1536),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_2])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_2])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_4])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_6])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_8])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf3, i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf5, i3 + 8 * i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_1,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type_1, clone_1, sort])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf13', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf10, i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type_2,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type_2])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf14', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf12, i3 + 8 * i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_3,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([sort_1, clone_3, convert_element_type_3])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=768),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_1])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=1536),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_2])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_2])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_4])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_6])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_8])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf3, i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf5, i3 + 8 * i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_1,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type_1, clone_1, sort])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf13', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf10, i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type_2,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type_2])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf14', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf12, i3 + 8 * i2)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_3,\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([sort_1, clone_3, convert_element_type_3])\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:06:24.847000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT from_kv_blocks c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\nn\\attention\\flex_attention.py line 299 \n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:06:25.181000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT _transpose_ordered c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\nn\\attention\\flex_attention.py line 186 \n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:06:25.360000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT _ordered_to_dense c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\nn\\attention\\flex_attention.py line 146 \n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:06:25.516000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT wrapped c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\apis.py line 202 \n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:06:25.677000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT _dense_to_ordered c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\nn\\attention\\flex_attention.py line 176 \n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                                              ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:06:25.719000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT flex_attention c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\nn\\attention\\flex_attention.py line 916 \n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1370, in load\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 859, in fx_codegen_and_compile\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     graph.run(*example_inputs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 780, in run\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return super().run(*args)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\fx\\interpreter.py\", line 146, in run\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.env[node] = self.run_node(node)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1319, in run_node\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = super().run_node(n)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\fx\\interpreter.py\", line 203, in run_node\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1024, in call_function\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise LoweringException(e, target, args, kwargs).with_traceback(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1021, in call_function\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = lowerings[target](*args, **kwargs)  # type: ignore[index]\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\lowering.py\", line 361, in wrapped\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = decomp_fn(*args, **kwargs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\kernel\\flex_attention.py\", line 849, in flex_attention\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     flex_attention_template.maybe_append_choice(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codegen\\common.py\", line 2158, in maybe_append_choice\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     choices.append(self.generate(**kwargs))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 678, in generate\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code = template.finalize_all()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 102, in finalize_all\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.code = self.code.replace(key, fn())\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                        ^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 306, in hook\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code.splice(self.jit_lines())\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                 ^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 232, in jit_lines\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     **TritonKernel.inductor_meta_common(),\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 2532, in inductor_meta_common\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\utils\\_triton.py\", line 51, in triton_hash_with_backend\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     from triton.compiler.compiler import triton_key\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._inductor.exc.LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_8', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_9', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_10', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_11', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_8', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_9', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_10', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_11', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\__init__.py\", line 2234, in __call__\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                ^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 588, in aot_dispatch_autograd\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1370, in load\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 859, in fx_codegen_and_compile\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     graph.run(*example_inputs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 780, in run\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return super().run(*args)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\fx\\interpreter.py\", line 146, in run\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.env[node] = self.run_node(node)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                      ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1319, in run_node\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = super().run_node(n)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\fx\\interpreter.py\", line 203, in run_node\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1024, in call_function\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise LoweringException(e, target, args, kwargs).with_traceback(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\graph.py\", line 1021, in call_function\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = lowerings[target](*args, **kwargs)  # type: ignore[index]\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\lowering.py\", line 361, in wrapped\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = decomp_fn(*args, **kwargs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\kernel\\flex_attention.py\", line 849, in flex_attention\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     flex_attention_template.maybe_append_choice(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codegen\\common.py\", line 2158, in maybe_append_choice\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     choices.append(self.generate(**kwargs))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 678, in generate\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code = template.finalize_all()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 102, in finalize_all\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.code = self.code.replace(key, fn())\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                                        ^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 306, in hook\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code.splice(self.jit_lines())\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                 ^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 232, in jit_lines\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     **TritonKernel.inductor_meta_common(),\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 2532, in inductor_meta_common\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\utils\\_triton.py\", line 51, in triton_hash_with_backend\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     from triton.compiler.compiler import triton_key\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._inductor.exc.LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_8', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_9', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_10', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_11', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]              ^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\huzhe\\miniconda3\\envs\\llm_scratch\\Lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_8', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_9', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_10', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_11', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W1216 15:06:25.888000 3148 site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "execution_stats = [time_pytorch_function_forward_backward(prepare_function(fn), embeddings) for fn in functions.values()]\n",
    "execution_means = [stat[0] for stat in execution_stats]\n",
    "execution_stds = [stat[1] for stat in execution_stats]\n",
    "\n",
    "\n",
    "plot_execution_times(functions, execution_means, execution_stds, filename=\"3_forward-and-backward-compiled.pdf\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llm_scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
